"""
Lambda Function: Embed Captions for Caption Index

Purpose: Generate embeddings for frame captions (from Feature 1.3)
         Matches Kubrick's approach: one embedding per caption (no chunking needed)

Triggered by: Manual invocation or EventBridge rule (after captions generated)

Input Event:
{
    "video_id": "test-video",
    "captions_s3_prefix": "test-video/caption_index"
}

Output:
- Caption embeddings stored in S3 for Caption Index (Bedrock KB #2)
- DynamoDB updated with caption_index_s3_prefix
- Status updated to "caption_index_ready"

Feature: 1.5 - Caption Index (NO chunking - already discrete captions)
"""

import json
import os
import boto3
from datetime import datetime
from decimal import Decimal
from typing import List, Dict

# AWS clients
s3_client = boto3.client('s3')
bedrock_runtime = boto3.client('bedrock-runtime', region_name=os.environ.get('AWS_REGION', 'us-east-1'))
bedrock_agent = boto3.client('bedrock-agent')
dynamodb = boto3.resource('dynamodb')
lambda_client = boto3.client('lambda')

# Environment variables
PROCESSED_BUCKET = os.environ['PROCESSED_BUCKET']
METADATA_TABLE = os.environ['METADATA_TABLE']
BEDROCK_EMBEDDING_MODEL = os.environ.get('BEDROCK_EMBEDDING_MODEL', 'amazon.titan-embed-text-v2:0')
CAPTION_KB_ID = os.environ.get('CAPTION_KB_ID')  # Caption Knowledge Base ID

# Cost tracking
COST_PER_EMBEDDING = 0.0001  # Approximate cost per Titan Text embedding


def load_captions_from_s3(video_id: str, captions_prefix: str) -> List[Dict]:
    """
    Load caption documents from S3 (generated by Feature 1.3)
    
    Args:
        video_id: Video identifier
        captions_prefix: S3 prefix for caption documents
    
    Returns:
        List of caption dictionaries
    """
    captions = []
    
    # List all caption documents in S3
    paginator = s3_client.get_paginator('list_objects_v2')
    pages = paginator.paginate(
        Bucket=PROCESSED_BUCKET,
        Prefix=f"{captions_prefix}/"
    )
    
    for page in pages:
        if 'Contents' not in page:
            continue
        
        for obj in page['Contents']:
            key = obj['Key']
            
            # Skip directories
            if key.endswith('/'):
                continue
            
            # Load caption document
            response = s3_client.get_object(Bucket=PROCESSED_BUCKET, Key=key)
            caption_doc = json.loads(response['Body'].read())
            
            captions.append(caption_doc)
    
    # Sort by frame number
    captions.sort(key=lambda c: c['frame_number'])
    
    return captions


def generate_embedding(text: str) -> List[float]:
    """
    Generate embedding using Bedrock Titan Text Embeddings
    
    Args:
        text: Text to embed
    
    Returns:
        Embedding vector (list of floats)
    """
    try:
        request_body = {
            "inputText": text
        }
        
        response = bedrock_runtime.invoke_model(
            modelId=BEDROCK_EMBEDDING_MODEL,
            contentType='application/json',
            accept='application/json',
            body=json.dumps(request_body)
        )
        
        response_body = json.loads(response['body'].read())
        embedding = response_body.get('embedding', [])
        
        return embedding
        
    except Exception as e:
        print(f"Error generating embedding: {str(e)}")
        return []


def handler(event, context):
    """
    Lambda handler: Generate embeddings for frame captions (no chunking needed)
    """
    print(f"Event: {json.dumps(event)}")
    
    # Parse event
    video_id = event['video_id']
    captions_prefix = event.get('captions_s3_prefix')
    frames_s3_prefix = event.get('frames_s3_prefix')
    
    # If prefixes not provided, derive them
    if not captions_prefix or not frames_s3_prefix:
        # Default paths based on convention
        if not captions_prefix:
            captions_prefix = f"{video_id}/caption_index"
        if not frames_s3_prefix:
            frames_s3_prefix = f"{video_id}/frames"
    
    print(f"Loading captions from: s3://{PROCESSED_BUCKET}/{captions_prefix}/")
    
    # Step 1: Load caption documents from S3
    print("Loading captions from S3...")
    captions = load_captions_from_s3(video_id, captions_prefix)
    
    if not captions:
        raise ValueError(f"No captions found at s3://{PROCESSED_BUCKET}/{captions_prefix}/")
    
    print(f"Loaded {len(captions)} captions")
    
    # Step 2: Generate embeddings for each caption (no chunking!)
    print("Generating embeddings for captions...")
    caption_index_docs = []
    
    for caption_doc in captions:
        frame_number = caption_doc['frame_number']
        caption_text = caption_doc['caption']
        frame_timestamp_sec = caption_doc['frame_timestamp_sec']
        
        # Generate embedding for caption
        embedding = generate_embedding(caption_text)
        
        if not embedding:
            print(f"Warning: Failed to generate embedding for frame {frame_number}")
            continue
        
        # Create caption index document (for Bedrock KB #2)
        # Note: Bedrock KB expects "text" field for content
        index_doc = {
            'video_id': video_id,
            'caption_id': f"{video_id}_frame_{frame_number:04d}",
            'frame_number': frame_number,
            'frame_timestamp_sec': frame_timestamp_sec,
            'text': caption_text,  # Bedrock KB expects "text" field
            'caption': caption_text,  # Keep for backward compat
            'embedding': embedding,
            'embedding_dimension': len(embedding),
            'metadata': {
                'generated_at': datetime.utcnow().isoformat(),
                'embedding_model': BEDROCK_EMBEDDING_MODEL,
                'source': 'frame_caption'  # Distinguish from speech
            }
        }
        
        caption_index_docs.append(index_doc)
        
        print(f"✓ Caption {frame_number}/{len(captions)}: frame at {frame_timestamp_sec:.1f}s")
    
    print(f"Generated {len(caption_index_docs)} caption embeddings")
    
    # Step 3: Upload caption index documents to S3
    # Store in separate prefix to distinguish from Feature 1.3 output
    caption_index_prefix = f"{video_id}/caption_embeddings"
    
    for doc in caption_index_docs:
        doc_key = f"{caption_index_prefix}/frame_{doc['frame_number']:04d}.json"
        
        # Create a clean copy WITHOUT embeddings for Bedrock KB
        # Bedrock KB generates its own embeddings from the "caption" field
        # Note: For captions, Bedrock KB will use "caption" as the text content
        clean_doc = {k: v for k, v in doc.items() if k not in ['embedding', 'embedding_dimension']}
        
        s3_client.put_object(
            Bucket=PROCESSED_BUCKET,
            Key=doc_key,
            Body=json.dumps(clean_doc, indent=2),
            ContentType='application/json'
        )
    
    print(f"✓ Uploaded {len(caption_index_docs)} documents to s3://{PROCESSED_BUCKET}/{caption_index_prefix}/")
    
    # Step 3.5: Trigger Bedrock KB ingestion to sync new documents
    try:
        print(f"Triggering Bedrock KB ingestion for Caption Index (KB: {CAPTION_KB_ID})...")
        
        # Get the data source ID for this KB
        data_sources_response = bedrock_agent.list_data_sources(knowledgeBaseId=CAPTION_KB_ID)
        data_source_id = data_sources_response['dataSourceSummaries'][0]['dataSourceId']
        
        # Start ingestion job
        ingestion_response = bedrock_agent.start_ingestion_job(
            knowledgeBaseId=CAPTION_KB_ID,
            dataSourceId=data_source_id
        )
        
        ingestion_job_id = ingestion_response['ingestionJob']['ingestionJobId']
        print(f"✅ Started KB ingestion job: {ingestion_job_id}")
        print(f"   Caption search will be available in ~2 minutes")
    except Exception as e:
        print(f"⚠️  Failed to trigger KB ingestion: {e}")
        print(f"   Caption index uploaded but may need manual KB sync")
    
    # Step 4: Update DynamoDB with caption index metadata
    estimated_cost = len(caption_index_docs) * COST_PER_EMBEDDING
    
    table = dynamodb.Table(METADATA_TABLE)
    table.update_item(
        Key={'video_id': video_id},
        UpdateExpression="""
            SET #status = :status,
                caption_embedding_count = :caption_count,
                caption_index_s3_prefix = :caption_index_prefix,
                processing_cost_estimate = processing_cost_estimate + :embedding_cost,
                updated_at = :timestamp
        """,
        ExpressionAttributeNames={
            '#status': 'status'
        },
        ExpressionAttributeValues={
            ':status': 'caption_index_ready',
            ':caption_count': len(caption_index_docs),
            ':caption_index_prefix': caption_index_prefix,
            ':embedding_cost': Decimal(str(round(estimated_cost, 4))),
            ':timestamp': datetime.utcnow().isoformat()
        }
    )
    
    print(f"✓ DynamoDB updated: status=caption_index_ready, caption_embedding_count={len(caption_index_docs)}")
    print(f"✓ Estimated cost: ${estimated_cost:.4f}")
    
    # Trigger embed_and_index_images Lambda to embed frames into Image Index
    try:
        lambda_client.invoke(
            FunctionName='mvip-embed-and-index-images',
            InvocationType='Event',  # Async invocation
            Payload=json.dumps({
                'video_id': video_id,
                'frames_prefix': frames_s3_prefix
            })
        )
        print(f"✅ Triggered embed_and_index_images for {video_id}")
    except Exception as e:
        print(f"⚠️  Failed to trigger embed_and_index_images: {e}")
        # Don't fail the whole process if image embedding trigger fails
    
    return {
        'statusCode': 200,
        'body': json.dumps({
            'video_id': video_id,
            'caption_embedding_count': len(caption_index_docs),
            'caption_index_s3_prefix': caption_index_prefix,
            'estimated_cost': round(estimated_cost, 4)
        })
    }

